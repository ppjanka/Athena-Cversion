\nonstopmode
\documentstyle[11pt]{article}

\setlength{\textheight}{9.0in}
\setlength{\textwidth}{6.5in}
\hoffset=-1.3 truecm
\voffset=-1.7 truecm

\newcommand{\SEP}[1]{\setlength{\fboxsep}{#1pt}}
\newsavebox{\Qbox}
\newenvironment{Ebox}{\hspace*{.1in}%
\begin{lrbox}{\Qbox}%
\begin{minipage}[t]{4.4in}\it\sffamily}%
{\end{minipage}%
\end{lrbox}\vspace{6pt}\SEP{6}%
\fbox{\usebox{\Qbox}}\vspace{6pt}\SEP{3}}



\newcommand{\ath}{{\tt athena3.1}}
\newcommand{\Dx}[0]{\bigtriangleup x}

\makeatletter                                            %KT
\@ifundefined{epsfbox}{\@input{epsf.sty}}{\relax}        %KT
\def\plotone#1{\centering \leavevmode                    %KT
\epsfxsize=\columnwidth \epsfbox{#1}}                    %KT
\def\plotone_reduction#1#2{\centering \leavevmode        %KT
\epsfxsize=#2\columnwidth \epsfbox{#1}}                  %KT
\def\plottwo#1#2{\centering \leavevmode                  %KT
\epsfxsize=.45\columnwidth \epsfbox{#1} \hfil            %KT
\epsfxsize=.45\columnwidth \epsfbox{#2}}                 %KT
\def\plotfiddle#1#2#3#4#5#6#7{\centering \leavevmode     %KT
\vbox to#2{\rule{0pt}{#2}}                               %KT
\special{psfile=#1 voffset=#7 hoffset=#6 vscale=#5 hscale=#4 angle=#3}} %KT
\makeatother


\begin{document}

\begin{center}
{\huge {\it The \ath\ User's Guide }} \vspace{1in} \\
{\Large James M. Stone, Thomas A. Gardiner} \\
{\large Department of Astrophysical Sciences \\ Princeton University \\
Princeton, NJ 08540} \vspace{0.5in} \\
{\Large Peter J. Teuben} \\
{\large Department of Astronomy \\ University of
Maryland \\ College Park MD 20742-2421} \vspace{0.5in} \\
and \vspace{0.5in} \\
{\Large John F. Hawley} \\
{\large Department of Astronomy \\ University of
Virginia \\ PO Box 3818 University Station \\ Charlottesville, VA 22903} \vspace{1in} \\
\end{center}
\newpage

\section{Introduction}

{\it Athena} is a grid-based code for astrophysical gas dynamics
developed with support of the NSF Information Technology Research (ITR)
program.  This {\it User's Guide} describes version 3.1 (hereafter
referred to as \ath); the third publicly released version of the code.

The \ath\ code contains algorithms for the following:
\begin{itemize}

\item compressible hydrodynamics and ideal MHD in one, two, or three spatial dimensions (Cartesian coordinates only),

\item ideal gas equation of state with arbitrary $\gamma$ (including 
$\gamma = 1$, an isothermal EOS),

\item second- or third-order reconstruction using the characteristic variables
(first-order interpolation is also available),

\item numerical fluxes computed using a variety of Riemann solvers (including
various solvers based on HLL fluxes, Roe's linearization, and exact solvers
in certain simple cases),

\item source terms due to a static gravitational potential,

\item self-gravity computed using FFTs,

\item an arbitrary number of passive scalars advected with the flow,

\item parallelization based on MPI.

\end{itemize}
It is strongly advised to use the latest release of
the code for research problems (even those in one-dimension) to take
advantage of improvements and potential bug fixes.

There are four basic sources of documentation for \ath:
\begin{enumerate}

\item {\it The Method Papers:} There are four in all: Gardiner \& Stone
(2005; 2008), Stone \& Gardiner (2008), and Stone et al. (2008).  By the
end of 2008, each of these are available on ADS, astro-ph, or with the
code distribution.

\item {\it The User's Guide:} (this document) gives an overview of how to
install, configure, compile, and run \ath\ and visualize the resulting output.

\item {\it The Programmer's Guide:} gives a basic introduction to the 
data structures, variable names, grid definitions, and code structure.

\item {\it Web-based Tutorials:} contains
instructions\footnote{{\tt http://www.astro.princeton.edu/$\sim$jstone/athena.html}}
for running problems from the \ath\ test suite, including examples of results.

\end{enumerate}
Users of \ath\ should have a basic, working knowledge of the Unix
operating system, access to a C compiler, and a graphics package for
plotting or animating one-, two-, and three-dimensional data.  Some familiarity
with code management using Makefiles is helpful but not necessary.

The code has been developed using the GNU development tools,
maintaining strict adherence to ANSI standards, thus it should be possible
to configure, compile, and run the code on any platform that supports these
standards.  It has been tested on Linux, MacOSX, and Solaris.

\subsection{Changes from {\tt athena3.0}}

The last publicly released version of the code was v3.0.  The current
version differs primarily in that it has more physics, in particulat the
advection of passive scalars, and self-gravity using FFTs.  Like v3.0,
this version implements two different unsplit, three-dimensional
algorithms; one based on CTU (Gardiner \& Stone 2008), and one based on
an algorithm due to van Leer (Stone \& Gardiner 2008).

In addition, there are a number of structural changes to the code, including:
(1) some files in {\tt /src} and {\tt src/prob} are renamed, and some new files are added,
(2) some options have changed in the configure script,
(3) there have been some bugs fixed in this version.

\subsection{Future versions}

The current developmental version of the code includes many more
algorithmic extensions than in this release, such as static and
adaptive mesh refinement, and radiation transfer.
It is likely that some of these extensions will be released in the future,
albeit on an irregular schedule.

\section{Quick Start}

To install, configure, compile, and run the code do the following.
\begin{enumerate}

\item Download\footnote{from {\tt http://www.astro.princeton.edu/$\sim$jstone/athena.html}}, uncompress, and untar the source code distribution file.

\item Create the configure script by running {\tt autoconf} in the
{\tt athena3.1} directory.

\item Test the install by running {\tt configure}; {\tt make all};
{\tt make test}.

\item If there are no errors in the previous step the install was
successful.  The code can now be re-configured, re-compiled, and used to run any
of the test problems in {\tt /src/prob}.

\end{enumerate}

\section{Getting Started}

\subsection{Obtaining and Installing \ath}

The source code for \ath\ can be downloaded as a gzipped tar file from the
web\footnotemark[2].  To install and run the code requires only a C compiler.

After downloading the tar file, uncompressing and untarring it,
the following directory structure should be created:

\begin{verbatim}
/athena3.1
          /doc            documentation, manuals
          /src            source code, and include files
              /prob       problem files (see /src/problem.c for a symbolic link)
          /tst            various input files for tests
              /1D-hydro
              /1D-mhd
              /2D-hydro
              /2D-mhd
              /3D-hydro
              /3D-mhd
          /vis            visualization tools and scripts
              /dx         OpenDX scripts
              /idl        IDL (rsinc.com) scripts
              /sm         Super Mongo scripts
              /vtk        code to join VTK legacy files
\end{verbatim}
In addition to the directories listed above (which are created when you
untar the source code), another directory will be created by the Makefile
when \ath\ is compiled for the first time, using {\tt make all}.

\begin{verbatim}
/athena3.1
          /bin           contains executable, created by Makefile
\end{verbatim}
(Trying to compile the code with {\tt make compile} before
{\tt make all} will result in an error since the {\tt bin} directory will
not yet exist.)

The {\tt athena3.1/doc} directory contains .pdf files of this document,
the {\em Programmer's Guide}, and the Method papers.  These documents serve as
the primary source of reference for the code, and should be consulted for
complete information.

\subsection{Configuring \ath}

After you have installed \ath\, the next step is to configure the
code for a specific problem.  To generate the {\tt configure} shell
script using the GNU {\tt autoconf} toolkit\footnote{autoconf: see {\tt
http://www.gnu.org/software/autoconf/}}, type {\tt autoconf} in the {\tt
athena3.1} directory.  If you wish to by-pass the configure script and work
with the Makefiles directly, see \S 3.4 below.

There are several basic functions served by the {\tt configure} script.
The first is to enable or disable {\it features} in the code, and to
choose between different {\it packages} implemented in \ath.  Configure
features are used when a particular option has only two choices:
enabled (``on") or disabled (``off"): examples include choosing whether
the executable uses single or double precision, or enabling or disabling
various data output formats.  Configure packages are used when an
option may have more than one choice.  Examples of packages include
the basic physics options (such as hydrodynamics or MHD, adiabatic or
isothermal equation of state, etc.), as well as the algorithm options
(order of accuracy for the reconstruction step, choice of Riemann solver,
etc.).  These package options are controlled at the source code
level using C precompiler macros.  The {\tt configure} script provides
a powerful way of setting these macros through a command line interface
that does not require the user to edit any special files.

More advanced features of the {\tt configure} script are to set compiler
and linker options and flags using environment variables, and to query the
system automatically to see that a C-compiler, linker, and any external
libraries necessary for compilation are installed and accessible.
Currently, only the former of these features are utilized.

Once the {\tt configure} script has been created, it can be used
with the following
syntax
\begin{center}
{\tt configure [--enable-{\it feature}] [--disable-{\it feature}]
[--with-{\it package}={\it choice}]},
\end{center}
where {\it feature} and {\it package}
are valid options in \ath, and {\it choice} is the value to which
{\it package} is to be set.  The valid optional features in \ath\ are given in
Table 1, and the valid optional packages (including all possible choices and
their default values) are given in Table 2\footnote{The file {\tt configure.ac}
contains the information auto-conf needs to generate the configure script
with these options.}.

\begin{table}[ht]
\caption{Optional features controlled by {\tt configure} in \ath}
\begin{center}
\begin{tabular}{|c|c|c|} \hline \hline
FEATURE & DEFAULT & Comments \\ \hline
single &  disabled & computations performed in single precision (default is double) \\
debug  & disabled & compiles code with flags needed for debugger \\
ghost  & disabled & causes ghost zones to be written during output \\
mpi    & disabled & parallelization using MPI library \\
h-correction & disabled & H-correction to fix carbuncle problem \\ 
fft & disabled & compile and link with FFTW block decomposition \\
\hline
\end{tabular}
\end{center}
%\\
\end{table}

\begin{table}[ht]
\caption{Optional packages controlled by configure in \ath}
\begin{center}
\begin{tabular}{|c|c|c|} \hline \hline
PACKAGE & CHOICE$^{a}$ & Comments \\ \hline
problem & {\it file-name} & use {\it file-name} in directory {\tt /src/prob} for initial conditions \\ \hline
gas    & hydro  & create code for hydrodynamics \\
       & {\bf mhd}    & create code for MHD \\ \hline
eos    & {\bf adiabatic} & use adiabatic equation of state \\
       & isothermal & use isothermal equation of state \\ \hline
nscalars & \# & add \# passively advected scalars (default is 0) \\ \hline
gravity & fft & enable self-gravity using FFTs \\ \hline
flux & {\bf roe} & Roe's Riemann solver \\
     & force & FORCE flux \\
     & hlle & HLLE Riemann solver \\
     & hllc & HLLC Riemann solver (hydrodynamics only) \\
     & hlld & HLLD Riemann solver (MHD only) \\ \hline
order & 1 & use first-order spatial reconstruction \\
      & {\bf 2} & use second-order (piecewise-linear) spatial reconstruction \\
      & 3 & use third-order (piecewise-parabolic) spatial reconstruction \\ \hline
integrator & {\bf ctu} & corner transport upwind unsplit integrator in 3D \\
           & vl & van Leer unsplit integrator in 3D \\
\hline
\end{tabular} \\
\end{center}
$^{a}$ Default choices shown in bold.
\end{table}

Only one choice can be made for each optional package given in Table 2
(the choices are mutually exclusive).  The ``problem" package should be
set to the file name in the directory {\tt athena3.1/src/prob} that is
to be used by the code to initialize the problem of interest.  A variety
of choices are included for the test problems that can be run by \ath\
(the default problem file is {\tt athena3.1/src/prob/linear\_wave1d.c},
{\it i.e.} {\tt --with-problem=linear\_wave1d}), these are described in
more detail in \S 6.  Note that {\tt configure} creates a symbolic link
between {\tt problem.c} in {\tt athena3.1/src} and the appropriate file
in {\tt athena3.1/src/prob}.

The {\tt configure} script should be run in the root directory {\tt
/athena3.1}.  Running {\tt configure} with the help option ({\tt configure
--help}) gives more information, including a list of all optional features
and packages.

For example, to configure \ath\ to run an isothermal hydrodynamical shocktube
problem initialized with the function {\tt shkset1d.c} problem
using Roe fluxes and third-order interpolation in single precision, use the
following:
\begin{center}
{\tt configure --with-problem=shkset1d --enable-single --with-eos=isothermal --with-gas=hydro --with-order=3}
\end{center}

To configure \ath\ to run the linear wave test problem in 3D adiabatic
MHD using HLLD fluxes, the van Leer integrator, and second-order interpolation in double precision
parallelized with MPI, use the following:
\begin{center}
{\tt configure --with-flux=hlld --with-problem=linear\_wave3d --with-integrator=vl --enable-mpi}
\end{center}

When {\tt configure} runs, it creates a custom {\tt Makefile} for the
problem in the directory {\tt athena3.1/src} using the file {\tt
athena3.1/src/Makefile.in} as a template.  After successful execution,
{\tt configure} will echo the options that have been set (including all
the default values).

\subsection{Compiling \ath}

After running {\tt configure}, all that is required to compile the code
is to type {\tt make all} in the top level directory {\tt /athena3.1}
(within which the configure script is run).  This automatically creates
the directory {\tt athena3.1/bin}, which will contain the executable,
and runs make in the {\tt athena3.1/src} directory to compile and link
the code.  The top-level Makefile in the {\tt /athena3.1} directory also
contains other targets listed in Table 3.

\begin{center}
\begin{table}[ht]
\caption{Some Makefile targets in \ath}
%\end{center}
\begin{tabular}{|c|c|} \hline \hline
TARGET & Comments \\ \hline
all & creates {\tt /athena3.1/bin} directory and compiles code \\
compile & compiles code \\
clean & removes .o files in {\tt /athena3.1/src} \\
help & prints help message \\
test & runs install test (see \S 10.1) \\
\hline
\end{tabular}
\end{table}
\end{center}

Normally the Makefiles should never be edited by hand.  However,
it is possible to edit the Makefile in the {\tt /athena3.1/src} directory to
change compiler flags (to improve optimization, for example)
rather than using
environment variables.  Just remember that the {\tt Makefile} is always 
overwritten every time {\tt configure} is run, so any custom changes may be
lost.

To make changes to the Makefile in the {\tt /athena3.1/src} that are permanent,
edit the template file {\tt /athena3.1/src/Makefile.in}.
For example, the best way to customize the compiler, options, flags,
and the path of local libraries is through the {\tt MACHINE=} option
on the make command line.  Currently, the options for several target machines are
included in {\tt Makefile.in}.  If no value for the {\tt MACHINE} option is
provided, the default is to use the {\tt gcc} compiler
with an optimization level of {\tt -O3}.  By using
\begin{verbatim}
% make all MACHINE=ophir
\end{verbatim}
the Intel C compiler (icc) with the options
{\tt -O2 -xW -tpp7 -ipo -i\_dynamic -gcc-name=gcc32} will be used.  To add
a new target machine, copy one of the machine targets in {\tt Makefile.in},
rename it, and edit as appropriate. 

\subsection{By-passing configure}

Most of the physics options in \ath\ are controlled by precompiler macros.  The
complete set of valid macros (some of which are mutually exclusive) are
defined in the file {\tt /src/defs.h.in}.  
The configure script creates a header file {\tt /src/defs.h} which contains
the appropriate set of macro definitions required for the given problem.
However, one can by-pass the configure script by creating and editing the
{\tt defs.h} file by hand (be warned that running configure at some later time
will overwrite this file).

Similarly, the compilation step is controlled by a Makefile generated by
the configure script from {\tt /src/Makefile.in}.  To bypass the configure
script, a custom Makefile must be created by hand from this template.
Again, remember that the {\tt Makefile} is always
overwritten every time {\tt configure} is run, so any custom changes may be
lost.

\subsection{Running \ath}

After configuring and compiling \ath, there should be an executable
called {\tt athena} in the directory {\tt athena3.1/bin}.  There
are two steps to running the code: (1) editing parameters in the
input file, and (2) running the executable.  Editing the input file is 
described in more detail in the subsections below.

The \ath\ executable can be run using the {\tt -i} option to specify the name of
the input file.  For example, to run the Brio \& Wu shocktube use
the command
\begin{verbatim}
  % athena -i ../tst/1D-mhd/athinput.brio-wu
\end{verbatim}
The code will first echo the values of all input parameters to stdout.
During the main integration loop
it will print the cycle number and timestep, and
when it concludes it will print final diagnostic information.

A variety of command line options have been implemented in \ath.
A list is given by the {\tt -h} switch:
\begin{verbatim}
  % athena -h
Athena version 3.1 - 01-JAN-2008
  Last configure: Wed Jan  9 09:25:53 EST 2008

Usage: athena [options] [block/par=value ...]

Options:
  -i <file>       Alternate input file [athinput]
  -d <directory>  Alternate run dir [current dir]
  -h              This Help, and configuration settings
  -n              Parse input, but don't run program
  -c              Show Configuration details and quit
  -r <file>       Restart a simulation with this file

Configuration details:

 Problem:                 linear_wave3d
 Gas properties:          MHD
 Equation of State:       ADIABATIC
 Passive scalars:         0
 Self-gravity:            none
 Order of Accuracy:       2 (SECOND_ORDER)
 Flux:                    hlld
 Unsplit 3D integrator:   ctu
 Precision:               DOUBLE_PREC
 Output Modes:
   Ghost Cells:           disabled
 Parallel Modes:
   MPI:                   MPI_SERIAL
 H-correction:            disabled
 FFT:                     disabled
\end{verbatim}
The {\tt -d} option can be used to create a new directory in which
\ath\ will run and write the output files.  The {\tt -n} option is
useful for debugging any parsing errors, as it will dump the contents
of all parsed block/parameters.

A value for any of the valid parameter names in the input file can
also be input from the command line, this over-rides the values in the
input file.  This, in combination with the {\tt -d} option, is useful
for parameter surveys.  The {\tt -c} option is useful for checking the
configuration parameters with which the executable was compiled.

\subsubsection{Editing the input file}

Run time parameters are set in an input file, usually given the name
{\tt athinput.}{\it problem-name}, where {\it problem-name} is a
string identifier.  Often this string is the same as the name of the
problem-generator, i.e. the function in {\tt athena3.1/src/prob} which
is used to initialize the data.  In some cases, a name which is more
specific to the problem at hand is used (since some problem-generators
can be used to initialize more than one problem).

As an example of an \ath\ input file, the file 
{\tt /athena3.1/tst/1D-mhd/athinput.brio-wu} is reproduced below.
Other examples can be found in the subdirectories in {\tt /athena3.1/tst/}.

\footnotesize
\begin{verbatim}
<comment>

problem = Brio & Wu shock tube
author  = M. Brio & C. C. Wu 
journal = J. Comp. Phys. 75, 400-422 (1988)
config  = --with-problem=shkset1d

<job>

problem_id      = Brio-Wu   # problem ID: basename of output filenames
maxout          = 3         # Output blocks number from 1 -> maxout

<output1>
out_fmt = tab               # Tabular data dump
dt      = 0.0025            # time increment between outputs

<output2>
out_fmt = hst               # History data dump
dt      = 0.0025            # time increment between outputs

<output3>
out_fmt = bin               # Binary data dump
dt      = 0.0025            # time increment between outputs

<time>

cour_no         = 0.8       # The Courant, Friedrichs, & Lewy (CFL) Number
nlim            = 10000     # cycle limit
tlim            = 0.1       # time limit

<grid>

Nx1             = 800       # Number of zones in X1-direction
x1min           = 0.0       # minimum value of X1
x1max           = 1.0       # maximum value of X1
ibc_x1          = 2         # inner (X1) boundary flag
obc_x1          = 2         # outer (X1) boundary flag

Nx2             = 1         # Number of zones in X2-direction
x2min           = 0.0       # minimum value of X2
x2max           = 1.0       # maximum value of X2
ibc_x2          = 2         # inner (X2) boundary flag
obc_x2          = 2         # outer (X2) boundary flag

Nx3             = 1         # Number of zones in X3-direction
x3min           = 0.0       # minimum value of X3
x3max           = 1.0       # maximum value of X3
ibc_x3          = 2         # inner (X3) boundary flag
obc_x3          = 2         # outer (X3) boundary flag

<parallel>

NGrid_x1 = 1
NGrid_x2 = 1
NGrid_x3 = 1

<problem>

gamma           = 2.0       # gamma = C_p/C_v

shk_dir         = 1         # Shock Direction -- (1,2,3) = (x1,x2,x3)

dl              = 1.0       # density on left half of grid
pl              = 1.0       # pressure
v1l             = 0.0       # X-velocity
v2l             = 0.0       # Y-velocity
v3l             = 0.0       # Z-velocity
b1l             = 0.75      # X-magnetic field
b2l             = 1.0       # Y-magnetic field
b3l             = 0.0       # Z-magnetic field

dr              = 0.125     # density on right half of grid
pr              = 0.1       # pressure
v1r             = 0.0       # X-velocity
v2r             = 0.0       # Y-velocity
v3r             = 0.0       # Z-velocity
b1r             = 0.75      # X-magnetic field
b2r             = -1.0      # Y-magnetic field
b3r             = 0.0       # Z-magnetic field
\end{verbatim}
\normalsize

Note the syntax of the parameter specification used in this file.
Parameters are grouped into named {\it blocks}, with the name of each
block appearing on a single line within angle brackets.  Block names
must always appear in angle brackets on a separate line (although the
blank lines above and below the block names are not required).

Below each block name is a list of parameters, with syntax
\begin{center}
 {\it parameter-name} = value [\# comments]
\end{center}
White space after the parameter name, after the `=', and before the
`\#' character is ignored.  Everything after (and including) the `\#'
character is also ignored.  Only one parameter value can appear per
line.  Comment lines (i.e. a line beginning with `\#') are allowed for
documentation purposes.  A maximum number of 256 characters is permitted
per line in the input file.  Both block names and parameter names are
case sensitive.

The input file is read by a very flexible parser written for \ath\
({\tt /athena3.1/src/par.c}).  The entire input file is read at the
very beginning of the main program, and the parameter names and their
values stored in memory.  Thereafter, these values can be accessed as
necessary by any function at any time during execution.  The parser
allows the parameter names to appear in any order within a named
block, extra (or misspelled) parameter names will be parsed and never
used.  There are no default values for any of the run-time parameters
in the input file; each parameter must be supplied a value through the
input file.  If a value is requested from the parser but its name does
not exist, the parser will print an error message and terminate the
execution of the program.  In this way, missing
parameter names will be detected at run time.  The parameters may be
integers, floating point numbers, or strings.  The parser will do
automatic type conversion, for example converting floating point
numbers to double precision if necessary (though the user is expected
to know the basic difference between real, integer, and string data
types).  Parameter values can also be set at run time through the
command line, which provides a very flexible way of testing the code
and running parameter searches,
using the syntax ``{\it block/parameter=value}''.

Below we describe each of the parameter blocks in the input file,
and the parameters they contain.

\subsubsection{The {\tt <comment>} block}

Provides self-documentation of the file.  The variables in this block
are not used in the code.

\subsubsection{The {\tt <job>} block}

Parameters in this block control properties of the jobs run by \ath.
They are accessed by the function {\tt main.c}.
\begin{itemize}

\item {\bf problem\_id:}
string added as basename of output filenames (see \S 4).  Usually same
as {\it problem-name} used in input file.  There is no maximum length
for this name\footnote{Although remember that the maximum length of a
line in the input file is 256 characters.}.

\item {\bf maxout:} Specifies how many output blocks will be read from
input file.  Output
blocks {\tt<output1>} through {\tt<outputN>} where {\tt N} = maxout
are scanned for valid output descriptions.  Missing output
blocks are permitted.

\end{itemize}

\subsubsection{The {\tt <output\#>} block}

Parameters in these blocks control the writing of ``outputs'',
e.g. data dumps, images, etc.
\begin{itemize}

\item {\bf out:} Variable to image for {\tt pgm, ppm, fits} output
formats.  Currently accepted values are: {\tt d, M1, M2, M3, E, B1c,
B2c, B3c, ME, V1, V2, V3, P, S, cs2}.  If variable is set to {\tt all},
then output will include {\tt d, M1, M2, M3} and may also include {\tt
E, B1c, B2c, B3c} depending on the configuration, and the output format
must be one of {\tt bin, dx, hst, tab, rst, vtk} (which can only dump
all rather than selected variables).

\item {\bf out\_fmt:} Output format, e.g.  
{\tt bin, dx, hst, tab, rst, vtk, fits, pdf, pgm, ppm}.  See \S 4 for more
description of these formats.

\item {\bf dat\_fmt:} Optional field for controlling the format string used 
to write tabular output files, e.g. {\tt \%12.5e}.  This value should
not appear in quotes and no white space should be present.

\item {\bf dt:} Time increment between outputs (in problem time).

\item {\bf time:} Time of next output (in problem time).  If not set,
the default will be the initial problem time (for new runs), or the
current problem time (for restarts).

\item {\bf id:} Any string, added to label output filenames.

\item {\bf dmin/dmax:} max/min applied to output (useful for images).

\item {\bf palette:} Color palette for images.  Currently available palettes
are {\tt rainbow, jh\_colors, idl1, idl2, step8, step32, heat}.

\item {\bf ix1, ix2, ix3:} Range of indices in x1, x2, or x3 directions over
which data is averaged.  For example {\tt ix1=:} will average over whole x1 axis
and dump a 2D array.  {\tt ix1=5:} will average from 5 to end. {\tt ix1=:10}
will average from start to 10. {\tt ix1=5:10} will average from 5 to 10.
{\tt x1=5} will extract the single plane at i index 5.

\item {\bf usr\_expr\_flag:} Set to 1 if a user-defined expression is to
be used to compute output quantity, see \S 4.2.

\end{itemize}

\subsubsection{The {\tt <time>} block}

Parameters in this block control times in a job (such as ending time).
They are accessed by the function {\tt main.c}.
\begin{itemize}

\item {\bf tlim:} Time to stop integration, in units defined by problem

\item {\bf nlim:} Maximum number of cycles of the main loop before stopping.
Set to -1 to stop only on time limit {\tt tlim}.

\item {\bf cour\_no:}  CFL number, must be less than 1.0 for 1D and 2D, 0.5
for 3D.

\end{itemize}

\subsubsection{The {\tt <grid>} block}

Parameters in this block control the properties of the grid. 
They are accessed by the function {\tt init\_grid\_block.c}.
\begin{itemize}

\item {\bf Nx1, Nx2, Nx3:} number of grid cells in the x1-, x2-, and x3-directions.

\item {\bf x1min, x2min, x3min:} x1-, x2-, x3-coordinate of left-edge of first cell

\item {\bf x1max, x2max, x3max:} x1-, x2-, x3-coordinate of right-edge of last cell.
The computational domain in the x1-direction spans $x1_{max}-x1_{min}$, the grid
spacing is $\Dx1=(x1_{max}-x1_{min})/Nx1$, and the center of the
first cell is located at $x1=x1_{min} + \Dx1/2$. Also, $x1_{max} >
x1_{min}$ is required.  Similarly for the computational domain in the 
x2- and x3-direction.

\item {\bf ibc\_x1, obc\_x1:} integer flags for boundary conditions applied
at ``inner" (left) and ``outer" (right) edges of grid.  Currently three
values are implemented: 1 = reflecting, 2 = outflow (projection), 
and 4 = periodic.  See \S 5 for more information.

\item {\bf ibc\_x2, obc\_x2:} Analogous parameters for the x2-direction.

\item {\bf ibc\_x3, obc\_x3:} Analogous parameters for the x3-direction.

\end{itemize}

\subsubsection{The {\tt <parallel>} block}

Parameters in this block control the decomposition of the computational
domain into MPI blocks.  The domain can be decomposed in any coordinate
direction, and into an arbitrary number of blocks.  This allows slab, pencil,
and block decompositions.
\begin{itemize}
\item {\bf NGrid\_x1:} Number of MPI blocks in the x1-direction.
\item {\bf NGrid\_x2:} Number of MPI blocks in the x2-direction.
\item {\bf NGrid\_x3:} Number of MPI blocks in the x3-direction.
\end{itemize}
This block can be omitted for serial jobs, or
the number of MPI blocks can be set to one in each dimension (as in the
example).

\subsubsection{The {\tt <problem>} block}

Parameters in this block are accessed by the problem-generator,
and therefore depend on the problem being run.  For example, the 
problem-generator {\tt athena3.1/src/prob/shkset1d.c}
(which is used for the Brio \& Wu test problem)
requires the following parameter values in the {\tt <problem>} block:
\begin{itemize}
\item {\bf gamma:} ratio of specific heats used in equation of state
\item {\bf *l:} values of variable * in left-state
\item {\bf *r:} values of variable * in right-state
\end{itemize}
The {\bf *l} and {\bf *r} parameter names are specific to the Brio \&
Wu shocktube problem.  In general, the input file for other problems
will have different variable names in the problem block.

\section{Data output formats}

As described above in \S 3.5.4, data output in the \ath\ code is
controlled by the {\tt <output>} blocks in the input file.  There should
be one block for each type of data output required.  There is no limit on
the total number of outputs.  Output filenames use a naming convention
{\it basename-id\#.dumpid.outid.type}, where the {\it basename} is inherited
from the {\tt <job>/problem\_id} parameter, the {\it -id\#} labels the
processor id for jobs run with MPI with {\it \#} an integer equal to the rank
of the MPI process (the root process does not contain an
{\it id\#}, nor is it present for serial jobs), the {\it dumpid} is a zero
filled unsigned integer with {\tt <job>/numdigits}\footnote{currently
fixed at four}, the {\it outid} is the string specified in {\tt <output>/id}
(if not specified, the string will be {\tt out-\#}, where {\tt \#}
denotes the block number in the input
file which generated the output), and the {\it type}
denotes the output format ({\tt bin, tab, hst, vtk, rst, pdf, pgm, ppm, fits}).
Note that history dump filenames do not include a {\it dumpid} or
{\it outid}.  Also note that none of the ``dump" formats (which output
all variables, that is any of {\tt bin, vtk, hst}) include the {\it outid}
string. 

The meaning of the parameters in the {\tt <output>} block has already been
described in \S 3.5.4.  Below we provide more information about each of the
output types.
\begin{enumerate}

\item {\bf History dumps:} ({\em type} = {\tt hst}) Formatted
table of a variety of volume integrated values, with one line in the
table created every {\tt <output>/dt}.  Thus, at the end of execution, the
output file contains $tlim/dt$ lines which form a time-history of these
quantities.  The file is created by the function {\tt dump\_history.c};
more (or problem specific) quantities can be added by editing this file.
The data is appended to the file each time the {\tt dump\_history()}
function is called.

\item {\bf Binary dumps:} ({\em type} = {\tt bin}) Unformatted
write of all dependent variables over all active zones.  If the {\tt dx}
option is enabled by configure, then an OpenDX header file with the same
name as the corresponding binary file but with the extension {\tt .dx}
will be created.  This header file allows binary dumps to be read by
OpenDX networks (see \S9.3).  A new file is created with a time interval
of {\tt <output>/dt}.  Created by the function {\tt dump\_binary.c}.

\item {\bf Tabular dumps:} ({\em type} = {\tt tab}) Formatted
table of all dependent variables overall all zones.  A new file is
created with a time interval of {\tt <output>/dt}.
Created by the function {\tt dump\_table.c}.  Useful for making 1D plots.

\item {\bf  ppm output:} ({\em type} = {\tt ppm}) Two dimensional images of
the variable set in the output block using the {\tt out} variable name.
Global scaling can be set using the parameters {\tt dmin} and {\tt
dmax} in the output block, otherwise each image is scaled independently.
A default color palette ({\tt rainbow}) is used, but several others are
available\footnote{see {\tt http://www.astro.princeton.edu/$\sim$jstone/athena\_color\_tables.html} for an index.}.  The image could be a
slice or an average over a range of grid cell indices whose orientation
is determined by the
values of {\tt <output>/ix1} (or {\tt <output>/ix2}, {\tt <output>/ix3}), 
see \S 3.5.4.  Created by the function
{\tt output\_ppm.c}.

\item {\bf  pgm output:} ({\em type} = {\tt pgm}) Grayscale images,
written in pgm format.  Scaling, orientation, and averaging used to
create slice is controlled in the same way as ppm outputs.
Created by the function {\tt output\_pgm.c}.

\item {\bf Probability distribution functions:} ({\em type} = {\tt pdf})
Outputs PDF of selected variables in tabular form.  Created by the
function {\tt output\_pdf.c}.

\item {\bf Flexible image transport system output:} ({\em type} = {\tt fits}) Same as ppm images,
but written in FITS\footnote{{\tt http://fits.gsfc.nasa.gov/}} format.
Created by the function {\tt output\_fits.c}.

\item {\bf Visualization Toolkit dumps:} ({\em type} = {\tt vtk})
Similar to binary dumps, but output written in VTK\footnote{\tt
http://www.vtk.org} legacy format.  Useful for 3D simulations.  Created by
the function {\tt dump\_vtk.c}.

\item {\bf Restart dumps:} ({\em type} = {\tt rst}) Creates a binary dump
of all variables (in double precision if necessary) that can be used to
restart a simulation.  The start of the restart file contains the entire
input file in ASCII.  For jobs run in parallel with MPI, there will be
one restart file per process.
See the next subsection for further details.

\end{enumerate}

\noindent
It is important to note that {\bf output files in \ath\ will always be
silently overwritten!} 

\subsection{More on Restarts}

Restart dumps (sometimes called {\em checkpoints}) are useful when a 
calculation must be continued from a previous point.  The files contain
enough information, and with the necessary accuracy, that a restart calculation
generates {\em identical} data (to all significant digits) to a calculation run
continuously.  {\tt Athena3.1} defines its
own format for restart files.  The file {\tt restart.c} contains all
the functions needed to read and write these files.

To write a restart file, add the following {\tt <output>} block to the
input file:
\begin{verbatim}
<output2>
out_fmt = rst            # Restart dump
dt      = 1.0            # time increment between outputs
\end{verbatim}
Note that {\tt <job>/maxout} must be greater than or equal to two in this
example.  The time increment {\tt <output>/dt} is measured in problem time, 
and should be set to give the desired output frequency of files
(usually writing one restart dump every 6 hours of wall clock time is useful).
For jobs run in parallel with MPI, there will be one restart file per process,
and the restarted job must use the same number of processors as there are
restart files.

If the problem contains special, user-defined data, these must be added to the
restart dumps.  {\tt Athena3.1} provides a mechanism for automatically adding
such data.  In the problem generator, two functions are provided:
\begin{verbatim}
void problem_write_restart(Grid *pG, Domain *pD, FILE *fp)
{
  return;
}

void problem_read_restart(Grid *pG, Domain *pD, FILE *fp)
{
  return;
}
\end{verbatim}
Generally these functions are empty, but if necessary they can be used
to read and write extra parameters, or set problem-specific boundary
conditions on restart, etc.  The problem generator {\tt src/prob/rt.c}
contains an example of usage.  See the {\em Programmer's Guide} for more
information about the structures in the argument list to these functions.

To read a restart file, the {\tt -r} command is used on the command line:
\begin{verbatim}
% athena -r myfile.rst
\end{verbatim}
Note that an input file, specified by {\tt -i myinput}, is not needed for
restarts.  This is because the restart file contains the original input file,
in ASCII format, at the beginning, from which all the necessary parameters
are read by {\tt par.c} on restart.  This also makes restart files self-documenting: the values of input parameters used in the calculation that generated
the restart file can be read with an editor.  If an input file is specified
along with a restart,
\begin{verbatim}
% athena -r myfile.rst -i myinput
\end{verbatim}
then the values in {\tt myinput} overwrite the values stored in the restart file
itself.  Alternatively, values in the input file can be overwritten using the
command line, for example:
\begin{verbatim}
% athena -r myfile.rst time/tlim=20.0
\end{verbatim}
Usually the {\tt time/tlim} parameter needs to be modified on restart.
For parallel jobs run with MPI, only the name of the restart file for the
root (rank 0) process needs to be specified, all other processes will 
create their own appropriate restart filename based on this name.

\subsection{Adding user-defined output expressions}

Often it is useful to output a variable other than one defined in the {\tt <output>/out} type
(see \S3.5.4)  using one of the valid formats listed in \S4.  For example,
one might like to create ppm images of the kinetic energy density.  This
can be easily accomplished using the {\tt <output>/usr\_expr\_flag}.  The
following steps are required.

Firstly, write a function that computes the desired variable.  It must be of
type {\tt Real}, and the argument list must contain the {\tt Gas}
structure and the indices of the grid cell.
(For details on the information contained in the {\tt Gas}
structure, see the {\it Programmer's Guide}.)
The following example, taken from {\tt src/prob/field\_loop.c}, computes the
$z-$component of the current density at cell $i,j,k$.
\begin{verbatim}
static Real current(const Grid *pG, const int i, const int j, const int k)
{
  return ((pG->B2i[k][j][i]-pG->B2i[k][j][i-1])/pG->dx1 -
          (pG->B1i[k][j][i]-pG->B1i[k][j-1][i])/pG->dx2);
}
\end{verbatim}

Next, use the function {\tt get\_usr\_expr()}, included in every
problem generator, to return the value computed by this function if the
string in {\tt <output>/out} has the appropriate value.  As an example,
the current density is computed using the function given above if the
{\tt <output>/out} string is `J3', with the following code
\begin{verbatim}
Gasfun_t get_usr_expr(const char *expr)
{
  if(strcmp(expr,"J3")==0) return current;
  return NULL;
}
\end{verbatim}

To create a movie of the current density, use an output block in the input
file in which {\tt <output>/out} is `J3', and {\tt <output>/usr\_expr\_flag=1},
with the other valid parameters set as appropriate (to control, for
example, the time interval between outputs, min/max scaling, etc.).
 
\subsection{Adding user-defined output formats} 

It is also fairly easy to add entirely new data output formats, beyond what
is provided for in \ath\ and described in \S4.
This can be accomplished in two steps.
The first step is to write a new output function in the file
containing the problem generator.  Suppose for example that the new
output function is called {\tt special\_output}.  It must have the
following prototype in the problem generator file
\begin{verbatim}
void special_output(Grid *pGrid, Domain *pDomain, Output *pOut);
\end{verbatim}
(For details on the information contained in the {\tt Grid}, {\tt Domain},
or {\tt Output} structures, see the {\it Programmer's Guide}.)  The second step
is to enroll this function by adding a call to {\tt
data\_output\_enroll} anywhere in the {\tt problem} routine.  The {\tt
data\_output\_enroll} function has the following prototype.
\begin{verbatim}
void data_output_enroll(Real time, Real dt, int num, const VGFunout_t fun,
                        const char *fmt, const Gasfun_t expr, int n,
                        const Real dmin, const Real dmax, int sdmin, int sdmax);
\end{verbatim}
The arguments to this function serve the following purpose.
\begin{itemize}

\item {\bf time:} Time of next output, usually the current simulation time.

\item {\bf dt:} The time interval between outputs.

\item {\bf num:} The initial data output number.

\item {\bf fun:} The name of the output function (a function pointer).  In
  the example above this is {\tt special\_output}, but it could also
  be say {\tt output\_ppm} for making images of some quantity.

\item {\bf fmt:} This is an optional format string used, for example,
  by {\tt dump\_table}.

\item {\bf expr:} The name of the function (a function pointer) of the
  quantity to be imaged when using an image type output routine,
  e.g. \{{\tt output\_ppm, output\_pgm, output\_fits}\}.

\item {\bf n}: Currently, image type outputs contain the string ``out\#'' 
in their file-name where the number ``\#'' is replaced with the argument 
{\bf n}.

\item {\bf dmin, dmax:} When making image type outputs, the data can 
either be auto-scaled to the min/max of the each image, or scaled to
the fixed values {\bf dmin / dmax}.

\item {\bf sdmin, sdmax:} Logical flags which indicate whether to use
auto-scaling ({\bf sdmin / sdmax} = 0) or to use the fixed scales
({\bf sdmin / sdmax} != 0).

\end{itemize}

In the simplest case the call to {\tt data\_output\_enroll} could take 
this form, where unused arguments are set to 0, or {\tt NULL}.
\begin{verbatim}
data_output_enroll(pGrid->time,0.1,0,special_output,NULL,NULL,0,0.0,0.0,0,0);
\end{verbatim}

\section{Specifying Boundary Conditions}

As described in \S 3.5.6, integer flags can be used to specify a limited set
of boundary conditions automatically in \ath.  The actual implementation of
the boundary conditions uses function pointers.  The
flags are used to enroll the appropriate default 
functions from the complete list in {\tt /src/set\_bvals.c}.  Each of these
functions sets quantities in the ghost zones according to the 
algorithm selected by the value of the flag.

The use of function pointers makes adding new boundary conditions for
specific problems quite easy.  For example, to add a new problem-specific
boundary condition along the inner X1 boundary, the user would (1)
write a new function which sets the values in the ghost zones and include
it in the
same file as the problem generator, and (2) enroll this new function by
adding the following line at the end of the problem generator
\begin{verbatim}
  set_bvals_fun(right_x1,special_bc_function_name);
\end{verbatim}

\noindent
where {\tt special\_bc\_function\_name} is the name of the special
function written in step (1).  The first argument of {\tt set\_bvals\_fun}
specifies the boundary on which the special function is enrolled; use
{\tt left\_x1} or {\tt right\_x1} for the inner or outer x1-boundary,
and similarly {\tt left\_x2} or {\tt right\_x2} specifies the inner or
outer x2-boundary respectively, and {\tt left\_x3} or {\tt right\_x3}
specifies the inner or outer x3-boundary respectively.  As examples,
users should look in the {\tt dmr.c}, {\tt noh.c}, and {\tt shkset3d.c}
problem generators; each contains special boundary functions enrolled
in this fashion.

Users should also note the following:

\begin{enumerate}

\item Boundary condition flags in the input file are only required for 
directions in which the grid is integrated.  That is, if {\tt Nx1>1}
and {\tt Nx2=Nx3=1}, then only ibc\_x1 and obc\_x1 are required in the
input file.  The parameters ibc\_x2, obc\_x2, ibc\_x3, and obc\_x3
may be present, but their value will not be checked.

\item If the user enrolls a boundary condition routine for say the inner
x1-boundary, the boundary condition flag ibc\_x1 in the parameter file
is not required.  Again it may be in the parameter file, but its value
will not be checked.

\end{enumerate}

\section{Problem Generators Included in \ath}

A large number of problem generators are included in the {\tt /src/prob}
directory.  The complete list is
\begin{verbatim}
blast.c      dmr.c            linear_wave3d.c  README       shkset2d.c
carbuncle.c  field_loop.c     lw_implode.c     rotor.c      shkset3d.c
cpaw1d.c     kh.c             noh.c            rt.c         shu-osher.c
cpaw2d.c     linear_wave1d.c  orszag-tang.c    shk_cloud.c  twoibw.c
cpaw3d.c     linear_wave2d.c  pgflow.c         shkset1d.c
\end{verbatim}
The {\tt README} file in this directory describes the purpose of each
problem.

\section{Gravity in \ath}

\subsection{Source terms due to a static potential}

The treatment of source terms in \ath\ is significantly different than
previous versions.  Now, only source terms due to a static gravitational
potential are allowed, and this treatment strictly conserves the total
energy in the flow.

To include a static gravitational potential in calculations, a
separate user-defined function which computes the gravitational potential
given the $(x_{1}, x_{2}, x_{3})$ coordinates as an input argument
must be specified in the problem generator file,
for example
\begin{verbatim}
static Real grav_pot(const Real x1, const Real x2, const Real x3);
\end{verbatim}
The arguments are the $x-$, $y-$, and $z-$coordinates
at which the potential is to be evaluated.  This function is then enrolled
into the integrator using a function pointer, called {\tt StaticGravPot}.
This pointer is defined in
{\tt src/globals.h}.  To enroll the user-defined function described in the
example above, add the line
\begin{verbatim}
  StaticGravPot = grav_pot;
\end{verbatim}
anywhere in the problem generator file.  If {\tt StaticGravPot},
is not specified in the problem
generator, then no gravitational acceleration will be included in the
integrator.

The problem files {\tt pgflow.c} and {\tt rt.c} are good examples
of how to include source terms in your own applications.  In particular,
{\tt pgflow.c} sets up a stringent test of gravitational source terms.

\subsection{Self-gravity using FFTs}

\ath includes the ability to include self-gravity of the fluid, computed
using FFTs.  A unique block decomposition of the FFT algorithm is used, based
on the FFTW libraries.  To use this feature, you must have the FFTW3.x
libraries installed, you must modify the options to the compiler in the
{\tt athena3.1/Makeoptions.in} file to link to these libraries, and
you must configure the code with the {\tt --with-gravity=fft --enable-fft}
options.  The numerical algorithm implemented in \ath conserves the total
momentum of the fluid exactly.   The gravitational constant is read as a 
parameter in the {\tt <problem>} block in the input file.
The linear wave test problems
included in the code distribution can be used to test the self-gravity
option.  Note the algorithm only works for periodic boundary conditions.

\section{Running \ath\ on multiple processors using MPI}

\ath\ is parallelized using domain decomposition based on the
Message Passing Interface\footnote{http://www-unix.mcs.anl.gov/mpi/} (MPI).
The code can be run on any distributed memory cluster (or any multiple
processor system) on which MPI is installed using the following steps.

Firstly, during the configure step, the MPI option must be enabled via
\begin{verbatim}
% configure --enable-mpi
\end{verbatim}
This sets precompiler macros to include the appropriate MPI code.

Next, during the compile step, the appropriate MPI libraries must be
linked.  Perhaps the easiest way to achieve this is to add an option
to {\tt src/Makefile.in} specifying the compiler, compiler options, linker,
and libraries specfic to the the target machine.  For example, using
\begin{verbatim}
% make all MACHINE=hydra
\end{verbatim}
includes the appropriate compiler and MPI libraries for a Beowulf cluster
at Princeton University called `hydra'.  By copying the options for hydra
to a new target machine `mymachine', editing them as appropriate, and
then compiling with
\begin{verbatim}
% make all MACHINE=mymachine
\end{verbatim}
the appropriate executable should be produced.

Next, the input file for the problem of interest must be edited to add
a {\tt <parallel>} block with that specifies the desired domain decomposition.
For example, the following block in the input file
\begin{verbatim}
<parallel>
NGrid_x1 = 1
NGrid_x2 = 10
NGrid_x3 = 1
\end{verbatim}
will result in a slab decomposition with 10 slabs in the $y-$direction
(a total of 10 processors are needed); while
\begin{verbatim}
<parallel>
NGrid_x1 = 1
NGrid_x2 = 2
NGrid_x3 = 3
\end{verbatim}
will result in a pencil decomposition with two pencils in the $y-$direction and
three in the $z-$direction (a total of 6 processors are needed); while
\begin{verbatim}
<parallel>
NGrid_x1 = 4
NGrid_x2 = 4
NGrid_x3 = 4
\end{verbatim}
will result in block decomposition with four blocks in each direction
(a total of 64 processors are needed).  Any decomposition is allowed,
although there can be no fewer than four active zones along any direction
in any MPI block.

Finally, the MPI job must be run using the {\tt mpiexec} or {\tt mpirun}
command.  The number of processors used must be specified e.g. through the
command line using {\tt -np \#} (where {\tt \#} specifies the number of
processors to be used).  The number of processors used at run time must
agree with the number of MPI blocks specified in the {\tt <parallel>}
block in the input file, or \ath\ will print an error message and
terminate.  A useful script for the Parallel Batch System (PBS) which
is often used to schedule jobs on parallel clusters is included in the
{\tt athena3.1/doc} directory.

Note that data generated by MPI parallel jobs will be written to separate files
for each process (except for history or pdf files, which contain the
appropriate MPI calls to do global sums).  A useful program for joining
together multiple vtk files generated by a parallel job is
included in {\tt athena3.1/vis/vtk}.

\section{Visualizing output}

{\tt Athena3.1} does not come with a default graphics package.  Instead,
the user must decide which visualization package is best suited to their
needs, output the data in a format which can be read by this package,
and then proceed.  As a start, rudimentary scripts for several different
graphics packages are supplied with the source code; future versions
may incorporate more sophisticated visualization tools.  The following
subsections describe useful visualization packages for \ath\ data files
(the discussion assumes the code has already been run to produce output).

\subsection{Supermongo}

A popular package for making publication-quality one-dimensional plots
is SM\footnote{{\tt http://www.astro.princeton.edu/$\sim$rhl/sm/}}.  A simple
SM macro that can read tabular output from \ath\ is provided in {\tt
athena3.1/vis/sm}.

\subsection{IDL procedures}

IDL (Interactive Data Language)\footnote{{\tt http://www.rsinc.com}}
procedures that can read both the binary and VTK dump files and make plots
are included in {\tt athena3.1/vis/idl}.  To run these procedures
IDL must be installed on the system.  From the {\tt athena3.1/bin} directory, use
the following to read a binary file and make some one-dimensional plots:
\begin{verbatim}
% idl
IDL> .run ../vis/idl/pltath.pro 
IDL> nine_plot,'Brio-Wu.0040.bin',1
\end{verbatim}
A variety of potentially useful
procedures are included in the {\tt pltath.pro} file.

\subsection{OpenDX networks}

The OpenDX\footnote{{\tt http://www.opendx.org}} package can
read \ath\ binary dump files, provided the {\tt .dx} header files exist.
This requires \ath\ be configured with the dx option enabled and of
course OpenDX must be installed on the system.  v2.0 of Athena included
an example network to read binary files, currently this network
has yet to be extended to \ath.

\subsection{VTK}

We have found the VisIt package\footnote{{\tt
http://www.llnl.gov/visit}} useful for plotting 3D data sets.  The VTK legacy
format produced by \ath\ can be read by VisIt.  For data created with
executables parallelized with MPI, a C code that joins multiple files into
one is provided in {\tt athena3.1/vis/vtk}.  This is useful for jobs run
on massively parallel clusters.

\subsection{2D animations}

{\tt Athena3.1} can output 2D images that can be displayed directly, or easily
turned into animations.  For example, if a series of ppm images of a single
variable have been created, they can be displayed either using
ImageMagick:
\begin{verbatim}
 % animate *.ppm
\end{verbatim}
or, alternatively, {\tt xanim} (which requires converting the ppm images to FLI
format):
\begin{verbatim}
 % ls Wind*ppm > list1
 % ppm2fli -g80x80 list1 Wind.fli
 % xanim Wind.fli
\end{verbatim}

\section{Examples of Running \ath}

\subsection{The \ath\ Benchmark}

To test the installation of \ath, a benchmark can be run automatically
using the Makefile.  This benchmark consists of a linear wave convergence
test on a grid of 512 zones; it computes and outputs the L1 error
norm in the fast magnetosonic wave compared to the analytic solution.
If the benchmark fails to run, or if the resulting error norm is large,
then something has gone wrong in the installation or in the compilation
of the code.

To run the benchmark, use the following commands (in the \ath\
root directory; these steps assume the configure script has already been generated with {\tt autoconf}).
\begin{verbatim}
% configure
% make all
% make test
(cd tst/1D-mhd; ./run.test)
zone-cycles/cpu-second = 3.067215e+05
zone-cycles/wall-second = 3.055470e+05
L1 norm for density: 6.333390e-11
\end{verbatim}
The {\tt zone-cycles/cpu-second} is a useful measure of the code performance,
it corresponds to the number of grid cells updated per cpu second.  This of
course depends on the physics included, the geometry of the problem, as well
as the processor used for the calculation.  The values reported above are
for a 3.08Ghz Intel Xeon processor.  The error norm is absolute, and should
never be larger than $10^{-10}$.

\subsection{Running a 1D test problem with \ath: The Brio \& Wu shocktube}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a one-dimensional test problem, we show the steps required 
to run the Brio \& Wu shocktube.
Assuming the code has already been installed (see \S2 or \S3), the first step is
to configure:
\begin{verbatim}
% cd athena3.1
% configure --with-problem=shkset1d
\end{verbatim}
The configure script will print a variety of diagnostic statements during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.1/bin} directory:
\begin{verbatim}
% cd bin
% athena -i ../tst/1D-mhd/athinput.brio-wu
\end{verbatim}
The code will print information about every timestep as it executes.  It
should generate 40 binary dumps named {\tt Brio-Wu.*.bin}, 40 tabular
dumps named {\tt Brio-Wu.*.tab},
as well as a history file {\tt Brio-Wu.hst}.  There
are a variety of ways that the data in these files can be visualized; one
way is to use the IDL scripts included in {\tt athena3.1/vis/idl}.
\begin{verbatim}
% idl
IDL> .r ../vis/idl/pltath.pro
IDL> four_plot,'Brio-Wu.0040.bin'
\end{verbatim}

The resulting plots which should now appear on the screen is shown in Figure 1. 

\begin{figure}[htb!]
\plotone_reduction{figure1.ps}{0.8}
\caption{Results from Brio \& Wu shocktube test problem plotting the using
IDL procedure {\tt four\_plot}}
\end{figure}

\subsection{Running a 2D test problem with \ath: The Orszag-Tang vortex}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a two-dimensional test problem, we show the steps required
to run the Orszag-Tang vortex test using the third order algorithm and the
HLLD fluxes.
Again, assuming the code has already been
installed (see \S2 or \S3), the first step is to configure:
\begin{verbatim}
% cd athena3.1
% configure --with-order=3 --with-problem=orszag-tang --with-flux=hlld
\end{verbatim}
A variety of diagnostic statements will be printed during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.1/bin} directory:
\begin{verbatim}
% cd bin
% athena -i ../tst/2D-mhd/athinput.orszag-tang
\end{verbatim}
The code will print information about every timestep as it executes.  On a 
3.08 GHz Xeon processor, the calculation takes about 4 minutes to complete.  It
should generate 100 binary dumps named {\tt OrszagTang.*.bin}, 250 ppm 
images of the gas pressure named {\tt OrszagTang.*.P.ppm}, 250 ppm
images of the density named {\tt OrszagTang.*.d.ppm},
as well as a history file {\tt OrszagTang.hst}.  There
are a variety of ways that the data in these files can be visualized; one
way is to use the IDL scripts included in {\tt athena3.1/vis/idl}.  To make a
contour plot of the pressure at time $t=0.5$, use the following:
\begin{verbatim}
% idl
IDL> .r ../vis/idl/pltath.pro
IDL> readbin,'OrszagTang.0050.bin'
IDL> contour,p,nlevels=30,/isotropic,xstyle=1,ystyle=1
\end{verbatim}

The resulting plot which should now appear on the screen is shown in Figure 2. 

\begin{figure}[htb!]
\plotone_reduction{figure2.ps}{0.8}
\caption{Contour plot of the gas pressure at time $t=0.5$ from
the Orszag-Tang test problem plotted using IDL.}
\end{figure}

It is also interesting to watch an animation of the density or
pressure in the problem.
This can be done a variety of ways.  The simplest is to use the ppm
images generated directly by the code.
For example, if ImageMagick is
installed on the system, try
\begin{verbatim}
% animate *.P.ppm
\end{verbatim}
The density can be animated in a similar fashion.

\subsection{Running a 3D test problem with \ath: Advection of a field loop}

As an example of how to configure, compile, and run \ath\ and visualize
the output for a three-dimensional test problem, we show the steps required 
to run the advection of a field loop test.
Again, assuming the code has already been
installed (see \S2 or \S3), the first step is to configure:
\begin{verbatim}
% cd athena3.1
% configure --with-order=3 --with-problem=field_loop --with-flux=hlld
\end{verbatim}
A variety of diagnostic statements will be printed during
this step.  Next, the code must be compiled:
\begin{verbatim}
% make all
\end{verbatim}
The default compiler options will print diagnostic statements.  Then
the code can be run in the {\tt athena3.1/bin} directory: 
\begin{verbatim}
% cd bin
% athena -i ../tst/3D-mhd/athinput.field_loop4 grid/Nx1=64 grid/Nx2=64 grid/Nx3=64
parallel/NGrid_x1=1 parallel/NGrid_x2=1 parallel/NGrid_x3=1
\end{verbatim}
Note the input file for the field loop test rotated at an angle is run
({\tt iprob=4} in the {\tt <problem>} block).  Since the
default input file for this problem uses a $128^3$ grid, with a block
decomposition on 8 processors using MPI, the command line is used to overwrite
the input parameters to use a $64^3$ grid and only one processor.

It will take about 30 minutes for this calculation to complete on a 3.08 GHz
Xeon processor.  The run should generate three VTK files, 250 ppm
images of the current density on a $x-y$ slice, and a history file.
A plot of an isosurface
 of the magnetic energy density made with the VisIt package is
shown in Figure 3.  Alternatively, the IDL procedure {\tt readvtk}
in {\tt vis/idl/pltath.pro} could be used to to read the data, and then one
of the plotting routines in IDL could be used to display the data.

\begin{figure}[htb!]
\plotone_reduction{figure3.ps}{0.8}
\caption{Surface plot of the magnetic energy, generated by VisIt, for
the advection of a rotated field loop in 3D.}
\end{figure}

\subsection{The \ath\ Test Suite}

Each of the problem generators in the {\tt /src/prob} subdirectory sets
up another test problem for \ath.  Further descriptions of these tests, and
examples of results from running \ath, can be found in the Athena code 
web pages, and in the Method papers.
  
\section{Running New Problems}

The real utility of the \ath\ code is as a solver for new problems
(i.e. problems that
are not initialized by the set of problem generators included in the source
code distribution).  For new problems, the following steps are required.
\begin{enumerate}
\item Write a new function that initializes the problem.  This function must
be of type {\tt void}, have the name {\tt problem}, and have as arguments
pointers to the {\tt Gas} and {\tt Domain} structures.
The function must be contained in a file in the {\tt /src/prob} directory.
\item Write new functions called {\tt Userwork\_in\_loop} and 
{\tt Userwork\_after\_loop} (which may be no-ops if not needed) and include
them in the file containing {\tt problem}.  As the names suggest, these
functions can be used to perform special problem-dependent work in or 
after the main loop (see {\tt linear\_wave.c} for an example).
\item If special purpose boundary conditions are needed, write special
functions that implement them, and enroll them using the function
{\tt set\_bvals\_fun} (see \S 5).
\item If special purpose data output is needed, write special
functions that implement them, and enroll them using the function
{\tt data\_output\_enroll} (see \S\S 4.2 and 4.3).
\item Once the above is complete, configure and compile the code
using the appropriate physics options, and including the new problem
generator using {\tt --with-problem=}{\em new-name}.
\end{enumerate}

It is likely the {\em Programmer's Guide} will be needed to write a 
new problem generator to understand the data structures and names used
in \ath.  As a start, the problem generators in {\tt /src/prob} can be used
as templates.

\end{document}
